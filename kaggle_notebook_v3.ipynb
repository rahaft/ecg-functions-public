{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Image Digitization - Kaggle Notebook Version 3\n",
    "\n",
    "**IMPORTANT:** Make sure to attach the competition dataset before running!\n",
    "\n",
    "**Version 3** includes:\n",
    "- Feature 1: Enhanced Grid Detection & Validation\n",
    "- Feature 1: Adaptive Line Detection Thresholds\n",
    "- Feature 1: Improved Grid Spacing Calculation\n",
    "- Performance optimizations ready for implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Grid Detection Module\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_1_grid_detection.py\n",
    "# Purpose: Cell 1 code for Kaggle notebook - Grid Detection\n",
    "# Usage: Copy entire file into Cell 1 of Kaggle notebook\n",
    "# Source: functions_python/grid_detection.py\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Enhanced Grid Detection Module\n",
    "Implements polynomial line fitting for ECG grid lines with oscillation detection\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "\n",
    "class GridDetector:\n",
    "    \"\"\"Enhanced grid detection with polynomial line fitting\"\"\"\n",
    "    \n",
    "    def __init__(self, max_polynomial_degree: int = 3):\n",
    "        \"\"\"\n",
    "        Initialize grid detector\n",
    "        \n",
    "        Args:\n",
    "            max_polynomial_degree: Maximum polynomial degree to use (1=linear, 2=quadratic, 3=cubic)\n",
    "        \"\"\"\n",
    "        self.max_polynomial_degree = max_polynomial_degree\n",
    "        self.grid_spacing_mm = 1.0  # mm per small square\n",
    "        \n",
    "    def detect_grid(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect ECG grid lines using Hough Transform and polynomial fitting\n",
    "        \n",
    "        Args:\n",
    "            image: Preprocessed binary image\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing detected lines, equations, and intersections\n",
    "        \"\"\"\n",
    "        # Detect horizontal and vertical lines using Hough Transform\n",
    "        horizontal_lines_raw, vertical_lines_raw = self._detect_lines_hough(image)\n",
    "        \n",
    "        # Fit polynomial equations to detected lines\n",
    "        horizontal_lines = self._fit_polynomial_lines(horizontal_lines_raw, 'horizontal', image.shape)\n",
    "        vertical_lines = self._fit_polynomial_lines(vertical_lines_raw, 'vertical', image.shape)\n",
    "        \n",
    "        # Validate lines for oscillation\n",
    "        horizontal_lines = self._validate_oscillation(horizontal_lines, 'horizontal', image.shape)\n",
    "        vertical_lines = self._validate_oscillation(vertical_lines, 'vertical', image.shape)\n",
    "        \n",
    "        # Find grid intersections\n",
    "        intersections = self._find_grid_intersections(horizontal_lines, vertical_lines, image.shape)\n",
    "        \n",
    "        # Calculate grid spacing\n",
    "        h_spacing = self._calculate_grid_spacing(horizontal_lines, image.shape[0])\n",
    "        v_spacing = self._calculate_grid_spacing(vertical_lines, image.shape[1])\n",
    "        \n",
    "        # FEATURE 1.1: Validate grid regularity\n",
    "        grid_quality = self._validate_grid_regularity(\n",
    "            horizontal_lines, vertical_lines, intersections\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'horizontal_lines': horizontal_lines,\n",
    "            'vertical_lines': vertical_lines,\n",
    "            'intersections': intersections,\n",
    "            'horizontal_spacing': h_spacing,\n",
    "            'vertical_spacing': v_spacing,\n",
    "            'image_shape': image.shape,\n",
    "            'grid_quality': grid_quality  # FEATURE 1.1: Grid quality metrics\n",
    "        }\n",
    "    \n",
    "    def _detect_lines_hough(self, image: np.ndarray) -> Tuple[List, List]:\n",
    "        \"\"\"Detect lines using Hough Transform with adaptive thresholds\"\"\"\n",
    "        # FEATURE 1.3: Adaptive edge detection based on image characteristics\n",
    "        image_mean = np.mean(image)\n",
    "        image_std = np.std(image)\n",
    "        \n",
    "        # Adjust Canny thresholds based on image contrast\n",
    "        if image_std < 30:  # Low contrast\n",
    "            low_threshold = 30\n",
    "            high_threshold = 100\n",
    "        elif image_std > 80:  # High contrast\n",
    "            low_threshold = 80\n",
    "            high_threshold = 200\n",
    "        else:  # Normal contrast\n",
    "            low_threshold = 50\n",
    "            high_threshold = 150\n",
    "        \n",
    "        edges = cv2.Canny(image, low_threshold, high_threshold, apertureSize=3)\n",
    "        \n",
    "        # Detect horizontal lines (theta near 0 or pi)\n",
    "        horizontal_lines = []\n",
    "        vertical_lines = []\n",
    "        \n",
    "        # FEATURE 1.3: Adaptive Hough parameters based on image size\n",
    "        # Adjust threshold based on image size\n",
    "        hough_threshold = max(50, int(min(image.shape) * 0.1))\n",
    "        min_line_length = max(30, int(min(image.shape) * 0.05))\n",
    "        \n",
    "        # Use Probabilistic Hough Transform for better performance\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=hough_threshold,\n",
    "                                minLineLength=min_line_length, maxLineGap=10)\n",
    "        \n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                \n",
    "                # Calculate angle\n",
    "                dx = x2 - x1\n",
    "                dy = y2 - y1\n",
    "                angle = np.arctan2(abs(dy), abs(dx)) * 180 / np.pi\n",
    "                \n",
    "                # Classify as horizontal or vertical\n",
    "                if angle < 15 or angle > 165:  # Horizontal (within 15 degrees)\n",
    "                    horizontal_lines.append((x1, y1, x2, y2))\n",
    "                elif 75 < angle < 105:  # Vertical (within 15 degrees)\n",
    "                    vertical_lines.append((x1, y1, x2, y2))\n",
    "        \n",
    "        return horizontal_lines, vertical_lines\n",
    "    \n",
    "    def _fit_polynomial_lines(self, raw_lines: List[Tuple], orientation: str, \n",
    "                             image_shape: Tuple[int, int]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fit polynomial equations to detected lines\n",
    "        \n",
    "        Args:\n",
    "            raw_lines: List of (x1, y1, x2, y2) line segments\n",
    "            orientation: 'horizontal' or 'vertical'\n",
    "            image_shape: (height, width) of image\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries with line equations and metadata\n",
    "        \"\"\"\n",
    "        if not raw_lines:\n",
    "            return []\n",
    "        \n",
    "        # Cluster lines that are close together\n",
    "        clustered_lines = self._cluster_lines(raw_lines, orientation, image_shape)\n",
    "        \n",
    "        fitted_lines = []\n",
    "        for cluster in clustered_lines:\n",
    "            # Extract points from all line segments in cluster\n",
    "            points = []\n",
    "            for line in cluster:\n",
    "                x1, y1, x2, y2 = line\n",
    "                # Sample points along the line\n",
    "                num_points = max(10, int(np.sqrt((x2-x1)**2 + (y2-y1)**2) / 5))\n",
    "                for i in range(num_points + 1):\n",
    "                    t = i / num_points\n",
    "                    x = x1 + t * (x2 - x1)\n",
    "                    y = y1 + t * (y2 - y1)\n",
    "                    points.append((x, y))\n",
    "            \n",
    "            if len(points) < 3:\n",
    "                continue\n",
    "            \n",
    "            points = np.array(points)\n",
    "            \n",
    "            # Fit polynomial of appropriate degree\n",
    "            line_data = self._fit_polynomial(points, orientation, image_shape)\n",
    "            if line_data:\n",
    "                fitted_lines.append(line_data)\n",
    "        \n",
    "        return fitted_lines\n",
    "    \n",
    "    def _cluster_lines(self, lines: List[Tuple], orientation: str, \n",
    "                      image_shape: Tuple[int, int]) -> List[List[Tuple]]:\n",
    "        \"\"\"Cluster lines that are close together\"\"\"\n",
    "        if not lines:\n",
    "            return []\n",
    "        \n",
    "        # Calculate representative position for each line\n",
    "        positions = []\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line\n",
    "            if orientation == 'horizontal':\n",
    "                # Use average y-coordinate\n",
    "                pos = (y1 + y2) / 2\n",
    "            else:\n",
    "                # Use average x-coordinate\n",
    "                pos = (x1 + x2) / 2\n",
    "            positions.append((pos, line))\n",
    "        \n",
    "        # Sort by position\n",
    "        positions.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Cluster lines within threshold distance\n",
    "        threshold = 10  # pixels\n",
    "        clusters = []\n",
    "        current_cluster = [positions[0][1]]\n",
    "        current_pos = positions[0][0]\n",
    "        \n",
    "        for pos, line in positions[1:]:\n",
    "            if abs(pos - current_pos) < threshold:\n",
    "                current_cluster.append(line)\n",
    "            else:\n",
    "                clusters.append(current_cluster)\n",
    "                current_cluster = [line]\n",
    "                current_pos = pos\n",
    "        \n",
    "        if current_cluster:\n",
    "            clusters.append(current_cluster)\n",
    "        \n",
    "        return clusters\n",
    "    \n",
    "    def _fit_polynomial(self, points: np.ndarray, orientation: str, \n",
    "                      image_shape: Tuple[int, int]) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Fit polynomial to points with adaptive degree selection\n",
    "        \n",
    "        Args:\n",
    "            points: Array of (x, y) points\n",
    "            orientation: 'horizontal' or 'vertical'\n",
    "            image_shape: (height, width) of image\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with polynomial coefficients and metadata\n",
    "        \"\"\"\n",
    "        if len(points) < 2:\n",
    "            return None\n",
    "        \n",
    "        # Sort points by x or y coordinate\n",
    "        if orientation == 'horizontal':\n",
    "            # For horizontal lines: y = f(x)\n",
    "            points = points[points[:, 0].argsort()]\n",
    "            x = points[:, 0]\n",
    "            y = points[:, 1]\n",
    "            domain_size = image_shape[1]\n",
    "        else:\n",
    "            # For vertical lines: x = f(y)\n",
    "            points = points[points[:, 1].argsort()]\n",
    "            x = points[:, 1]\n",
    "            y = points[:, 0]\n",
    "            domain_size = image_shape[0]\n",
    "        \n",
    "        # Try different polynomial degrees and select best\n",
    "        best_degree = 1\n",
    "        best_r2 = -np.inf\n",
    "        best_coeffs = None\n",
    "        \n",
    "        for degree in range(1, min(self.max_polynomial_degree + 1, len(points))):\n",
    "            try:\n",
    "                coeffs = np.polyfit(x, y, degree)\n",
    "                poly_func = np.poly1d(coeffs)\n",
    "                y_pred = poly_func(x)\n",
    "                \n",
    "                # Calculate R-squared\n",
    "                ss_res = np.sum((y - y_pred) ** 2)\n",
    "                ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "                if ss_tot > 0:\n",
    "                    r2 = 1 - (ss_res / ss_tot)\n",
    "                else:\n",
    "                    r2 = 0\n",
    "                \n",
    "                # Prefer lower degree if R2 is similar (within 0.01)\n",
    "                if r2 > best_r2 + 0.01 or (r2 > best_r2 - 0.01 and degree < best_degree):\n",
    "                    best_degree = degree\n",
    "                    best_r2 = r2\n",
    "                    best_coeffs = coeffs\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if best_coeffs is None:\n",
    "            return None\n",
    "        \n",
    "        # Create polynomial function\n",
    "        poly_func = np.poly1d(best_coeffs)\n",
    "        \n",
    "        return {\n",
    "            'coefficients': best_coeffs.tolist(),\n",
    "            'degree': best_degree,\n",
    "            'r_squared': float(best_r2),\n",
    "            'orientation': orientation,\n",
    "            'domain': (float(x.min()), float(x.max())),\n",
    "            'range': (float(y.min()), float(y.max())),\n",
    "            'function': poly_func\n",
    "        }\n",
    "    \n",
    "    def _validate_oscillation(self, lines: List[Dict], orientation: str, \n",
    "                             image_shape: Tuple[int, int]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Validate that higher-order lines don't oscillate away from reference\n",
    "        \n",
    "        Args:\n",
    "            lines: List of line dictionaries\n",
    "            orientation: 'horizontal' or 'vertical'\n",
    "            image_shape: (height, width) of image\n",
    "            \n",
    "        Returns:\n",
    "            Filtered list of valid lines\n",
    "        \"\"\"\n",
    "        if orientation == 'horizontal':\n",
    "            # For horizontal lines, check they don't oscillate vertically\n",
    "            # Compare with linear fit\n",
    "            valid_lines = []\n",
    "            for line in lines:\n",
    "                if line['degree'] == 1:\n",
    "                    valid_lines.append(line)\n",
    "                else:\n",
    "                    # Check oscillation by comparing with linear fit\n",
    "                    x_min, x_max = line['domain']\n",
    "                    x_test = np.linspace(x_min, x_max, 100)\n",
    "                    y_poly = line['function'](x_test)\n",
    "                    \n",
    "                    # Fit linear to same points\n",
    "                    y_linear = np.polyval(np.polyfit(x_test, y_poly, 1), x_test)\n",
    "                    \n",
    "                    # Check maximum deviation\n",
    "                    max_deviation = np.max(np.abs(y_poly - y_linear))\n",
    "                    \n",
    "                    # Allow small deviation (5 pixels)\n",
    "                    if max_deviation < 5:\n",
    "                        valid_lines.append(line)\n",
    "                    else:\n",
    "                        # Replace with linear fit\n",
    "                        coeffs_linear = np.polyfit(x_test, y_poly, 1)\n",
    "                        line['coefficients'] = coeffs_linear.tolist()\n",
    "                        line['degree'] = 1\n",
    "                        line['function'] = np.poly1d(coeffs_linear)\n",
    "                        valid_lines.append(line)\n",
    "        else:\n",
    "            # For vertical lines, check they don't oscillate horizontally\n",
    "            valid_lines = []\n",
    "            for line in lines:\n",
    "                if line['degree'] == 1:\n",
    "                    valid_lines.append(line)\n",
    "                else:\n",
    "                    y_min, y_max = line['domain']\n",
    "                    y_test = np.linspace(y_min, y_max, 100)\n",
    "                    x_poly = line['function'](y_test)\n",
    "                    \n",
    "                    # Fit linear to same points\n",
    "                    x_linear = np.polyval(np.polyfit(y_test, x_poly, 1), y_test)\n",
    "                    \n",
    "                    # Check maximum deviation\n",
    "                    max_deviation = np.max(np.abs(x_poly - x_linear))\n",
    "                    \n",
    "                    # Allow small deviation (5 pixels)\n",
    "                    if max_deviation < 5:\n",
    "                        valid_lines.append(line)\n",
    "                    else:\n",
    "                        # Replace with linear fit\n",
    "                        coeffs_linear = np.polyfit(y_test, x_poly, 1)\n",
    "                        line['coefficients'] = coeffs_linear.tolist()\n",
    "                        line['degree'] = 1\n",
    "                        line['function'] = np.poly1d(coeffs_linear)\n",
    "                        valid_lines.append(line)\n",
    "        \n",
    "        return valid_lines\n",
    "    \n",
    "    def _find_grid_intersections(self, horizontal_lines: List[Dict], \n",
    "                                 vertical_lines: List[Dict],\n",
    "                                 image_shape: Tuple[int, int]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Find intersections between horizontal and vertical grid lines\n",
    "        \n",
    "        Args:\n",
    "            horizontal_lines: List of horizontal line dictionaries\n",
    "            vertical_lines: List of vertical line dictionaries\n",
    "            image_shape: (height, width) of image\n",
    "            \n",
    "        Returns:\n",
    "            List of intersection points\n",
    "        \"\"\"\n",
    "        intersections = []\n",
    "        \n",
    "        for h_line in horizontal_lines:\n",
    "            for v_line in vertical_lines:\n",
    "                intersection = self._solve_intersection(h_line, v_line, image_shape)\n",
    "                if intersection:\n",
    "                    intersections.append(intersection)\n",
    "        \n",
    "        return intersections\n",
    "    \n",
    "    def _solve_intersection(self, h_line: Dict, v_line: Dict, \n",
    "                           image_shape: Tuple[int, int]) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Solve intersection between horizontal and vertical polynomial lines\n",
    "        \n",
    "        For horizontal: y = f_h(x)\n",
    "        For vertical: x = f_v(y)\n",
    "        \n",
    "        Solve: x = f_v(f_h(x))\n",
    "        \"\"\"\n",
    "        try:\n",
    "            h_func = h_line['function']\n",
    "            v_func = v_line['function']\n",
    "            \n",
    "            # Get overlapping domain\n",
    "            h_x_min, h_x_max = h_line['domain']\n",
    "            v_y_min, v_y_max = v_line['domain']\n",
    "            \n",
    "            # Sample points to find intersection\n",
    "            x_samples = np.linspace(h_x_min, h_x_max, 100)\n",
    "            y_samples = h_func(x_samples)\n",
    "            \n",
    "            # Find where vertical line intersects\n",
    "            valid_indices = (y_samples >= v_y_min) & (y_samples <= v_y_max)\n",
    "            if not np.any(valid_indices):\n",
    "                return None\n",
    "            \n",
    "            x_valid = x_samples[valid_indices]\n",
    "            y_valid = y_samples[valid_indices]\n",
    "            \n",
    "            # Calculate x from vertical line\n",
    "            x_from_v = v_func(y_valid)\n",
    "            \n",
    "            # Find where x matches\n",
    "            differences = np.abs(x_valid - x_from_v)\n",
    "            min_idx = np.argmin(differences)\n",
    "            \n",
    "            if differences[min_idx] < 5:  # Within 5 pixels\n",
    "                x_int = x_valid[min_idx]\n",
    "                y_int = y_valid[min_idx]\n",
    "                \n",
    "                # Ensure within image bounds\n",
    "                if 0 <= x_int < image_shape[1] and 0 <= y_int < image_shape[0]:\n",
    "                    return {\n",
    "                        'x': float(x_int),\n",
    "                        'y': float(y_int)\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error solving intersection: {e}\")\n",
    "            return None\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _calculate_grid_spacing(self, lines: List[Dict], dimension_size: int) -> float:\n",
    "        \"\"\"Calculate average grid spacing with improved outlier rejection\"\"\"\n",
    "        if len(lines) < 2:\n",
    "            return 10.0  # Default spacing\n",
    "        \n",
    "        # Extract representative positions\n",
    "        positions = []\n",
    "        for line in lines:\n",
    "            if line['orientation'] == 'horizontal':\n",
    "                # Use y-value at middle of domain\n",
    "                x_mid = (line['domain'][0] + line['domain'][1]) / 2\n",
    "                y_mid = line['function'](x_mid)\n",
    "                positions.append(y_mid)\n",
    "            else:\n",
    "                # Use x-value at middle of domain\n",
    "                y_mid = (line['domain'][0] + line['domain'][1]) / 2\n",
    "                x_mid = line['function'](y_mid)\n",
    "                positions.append(x_mid)\n",
    "        \n",
    "        positions = sorted(positions)\n",
    "        \n",
    "        if len(positions) < 2:\n",
    "            return 10.0\n",
    "        \n",
    "        # FEATURE 1.2: Calculate spacings with improved method\n",
    "        spacings = np.diff(positions)\n",
    "        \n",
    "        # Method 1: Median of valid spacings (existing approach)\n",
    "        median_spacing = np.median(spacings)\n",
    "        valid_spacings = spacings[np.abs(spacings - median_spacing) < median_spacing * 0.5]\n",
    "        \n",
    "        # FEATURE 1.2: Method 2: Mode-based (most common spacing)\n",
    "        if len(spacings) > 5:\n",
    "            # Bin spacings and find mode\n",
    "            bins = np.linspace(spacings.min(), spacings.max(), 20)\n",
    "            hist, bin_edges = np.histogram(spacings, bins=bins)\n",
    "            mode_bin = np.argmax(hist)\n",
    "            mode_spacing = (bin_edges[mode_bin] + bin_edges[mode_bin + 1]) / 2\n",
    "            \n",
    "            # Use mode if it's close to median, otherwise use median\n",
    "            if abs(mode_spacing - median_spacing) < median_spacing * 0.2:\n",
    "                return float(mode_spacing)\n",
    "        \n",
    "        # Return median of valid spacings\n",
    "        if len(valid_spacings) > 0:\n",
    "            return float(np.median(valid_spacings))\n",
    "        \n",
    "        return 10.0  # Default spacing\n",
    "    \n",
    "    def _validate_grid_regularity(self, h_lines: List[Dict], v_lines: List[Dict], \n",
    "                                   intersections: List[Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        FEATURE 1.1: Validate that grid is regular and well-formed\n",
    "        \n",
    "        Args:\n",
    "            h_lines: List of horizontal line dictionaries\n",
    "            v_lines: List of vertical line dictionaries\n",
    "            intersections: List of intersection points\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with grid quality metrics\n",
    "        \"\"\"\n",
    "        quality = {\n",
    "            'is_regular': True,\n",
    "            'spacing_variance': 0.0,\n",
    "            'missing_lines': 0,\n",
    "            'warnings': []\n",
    "        }\n",
    "        \n",
    "        # Check horizontal spacing consistency\n",
    "        if len(h_lines) > 1:\n",
    "            h_positions = []\n",
    "            for line in h_lines:\n",
    "                x_mid = (line['domain'][0] + line['domain'][1]) / 2\n",
    "                y_mid = line['function'](x_mid)\n",
    "                h_positions.append(y_mid)\n",
    "            \n",
    "            h_positions = sorted(h_positions)\n",
    "            h_spacings = np.diff(h_positions)\n",
    "            \n",
    "            if len(h_spacings) > 0:\n",
    "                h_variance = float(np.var(h_spacings))\n",
    "                quality['spacing_variance'] = max(quality['spacing_variance'], h_variance)\n",
    "                \n",
    "                if h_variance > 100:  # Threshold for irregular spacing\n",
    "                    quality['is_regular'] = False\n",
    "                    quality['warnings'].append(f\"High horizontal spacing variance: {h_variance:.2f}\")\n",
    "        \n",
    "        # Check vertical spacing consistency\n",
    "        if len(v_lines) > 1:\n",
    "            v_positions = []\n",
    "            for line in v_lines:\n",
    "                y_mid = (line['domain'][0] + line['domain'][1]) / 2\n",
    "                x_mid = line['function'](y_mid)\n",
    "                v_positions.append(x_mid)\n",
    "            \n",
    "            v_positions = sorted(v_positions)\n",
    "            v_spacings = np.diff(v_positions)\n",
    "            \n",
    "            if len(v_spacings) > 0:\n",
    "                v_variance = float(np.var(v_spacings))\n",
    "                quality['spacing_variance'] = max(quality['spacing_variance'], v_variance)\n",
    "                \n",
    "                if v_variance > 100:  # Threshold for irregular spacing\n",
    "                    quality['is_regular'] = False\n",
    "                    quality['warnings'].append(f\"High vertical spacing variance: {v_variance:.2f}\")\n",
    "        \n",
    "        # Check for expected number of intersections\n",
    "        expected_intersections = len(h_lines) * len(v_lines)\n",
    "        if len(intersections) < expected_intersections * 0.5:\n",
    "            quality['warnings'].append(\n",
    "                f\"Missing intersections: {len(intersections)}/{expected_intersections} \"\n",
    "                f\"({len(intersections)/expected_intersections*100:.1f}%)\"\n",
    "            )\n",
    "            if len(intersections) < expected_intersections * 0.3:\n",
    "                quality['is_regular'] = False\n",
    "        \n",
    "        # Check for minimum required lines\n",
    "        if len(h_lines) < 3:\n",
    "            quality['warnings'].append(f\"Few horizontal lines detected: {len(h_lines)}\")\n",
    "            quality['missing_lines'] += (3 - len(h_lines))\n",
    "        \n",
    "        if len(v_lines) < 3:\n",
    "            quality['warnings'].append(f\"Few vertical lines detected: {len(v_lines)}\")\n",
    "            quality['missing_lines'] += (3 - len(v_lines))\n",
    "        \n",
    "        return quality\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Grid Detection Module\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_1_grid_detection.py\n",
    "# Purpose: Cell 1 code for Kaggle notebook - Grid Detection\n",
    "# Usage: Copy entire file into Cell 1 of Kaggle notebook\n",
    "# Source: functions_python/grid_detection.py\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Segmented Processing Module\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_2_segmented_processing.py\n",
    "# Purpose: Cell 2 code for Kaggle notebook - Segmented Processing\n",
    "# Usage: Copy entire file into Cell 2 of Kaggle notebook\n",
    "# Source: functions_python/segmented_processing.py\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Segmented Processing Module\n",
    "Processes images in overlapping segments with different parameters per segment\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Segment:\n",
    "    \"\"\"Represents an image segment\"\"\"\n",
    "    x_start: int\n",
    "    x_end: int\n",
    "    y_start: int\n",
    "    y_end: int\n",
    "    overlap_left: int = 0\n",
    "    overlap_right: int = 0\n",
    "    overlap_top: int = 0\n",
    "    overlap_bottom: int = 0\n",
    "    parameters: Optional[Dict] = None\n",
    "\n",
    "\n",
    "class SegmentedProcessor:\n",
    "    \"\"\"Process images in overlapping segments\"\"\"\n",
    "    \n",
    "    def __init__(self, overlap_ratio: float = 0.2, min_segment_size: int = 100):\n",
    "        \"\"\"\n",
    "        Initialize segmented processor\n",
    "        \n",
    "        Args:\n",
    "            overlap_ratio: Ratio of segment size to use for overlap (0.0 to 0.5)\n",
    "            min_segment_size: Minimum segment size in pixels\n",
    "        \"\"\"\n",
    "        self.overlap_ratio = overlap_ratio\n",
    "        self.min_segment_size = min_segment_size\n",
    "    \n",
    "    def create_segments(self, image_shape: Tuple[int, int], \n",
    "                       segment_size: Optional[Tuple[int, int]] = None,\n",
    "                       num_segments: Optional[Tuple[int, int]] = None) -> List[Segment]:\n",
    "        \"\"\"\n",
    "        Create overlapping segments for an image\n",
    "        \n",
    "        Args:\n",
    "            image_shape: (height, width) of image\n",
    "            segment_size: (height, width) of each segment (if specified)\n",
    "            num_segments: (num_rows, num_cols) of segments (if specified)\n",
    "            \n",
    "        Returns:\n",
    "            List of Segment objects\n",
    "        \"\"\"\n",
    "        height, width = image_shape\n",
    "        \n",
    "        if segment_size is not None:\n",
    "            seg_height, seg_width = segment_size\n",
    "            num_rows = max(1, int(np.ceil(height / seg_height)))\n",
    "            num_cols = max(1, int(np.ceil(width / seg_width)))\n",
    "        elif num_segments is not None:\n",
    "            num_rows, num_cols = num_segments\n",
    "            seg_height = height // num_rows\n",
    "            seg_width = width // num_cols\n",
    "        else:\n",
    "            # Default: divide into 4 segments\n",
    "            num_rows = 2\n",
    "            num_cols = 2\n",
    "            seg_height = height // num_rows\n",
    "            seg_width = width // num_cols\n",
    "        \n",
    "        # Ensure minimum segment size\n",
    "        seg_height = max(self.min_segment_size, seg_height)\n",
    "        seg_width = max(self.min_segment_size, seg_width)\n",
    "        \n",
    "        # Calculate overlap\n",
    "        overlap_h = int(seg_height * self.overlap_ratio)\n",
    "        overlap_w = int(seg_width * self.overlap_ratio)\n",
    "        \n",
    "        segments = []\n",
    "        \n",
    "        for row in range(num_rows):\n",
    "            for col in range(num_cols):\n",
    "                # Calculate segment boundaries\n",
    "                y_start = row * seg_height\n",
    "                y_end = min((row + 1) * seg_height, height)\n",
    "                x_start = col * seg_width\n",
    "                x_end = min((col + 1) * seg_width, width)\n",
    "                \n",
    "                # Calculate overlaps\n",
    "                overlap_left = overlap_w if col > 0 else 0\n",
    "                overlap_right = overlap_w if col < num_cols - 1 else 0\n",
    "                overlap_top = overlap_h if row > 0 else 0\n",
    "                overlap_bottom = overlap_h if row < num_rows - 1 else 0\n",
    "                \n",
    "                # Adjust boundaries to include overlap\n",
    "                y_start_adj = max(0, y_start - overlap_top)\n",
    "                y_end_adj = min(height, y_end + overlap_bottom)\n",
    "                x_start_adj = max(0, x_start - overlap_left)\n",
    "                x_end_adj = min(width, x_end + overlap_right)\n",
    "                \n",
    "                segment = Segment(\n",
    "                    x_start=x_start_adj,\n",
    "                    x_end=x_end_adj,\n",
    "                    y_start=y_start_adj,\n",
    "                    y_end=y_end_adj,\n",
    "                    overlap_left=overlap_left if col > 0 else 0,\n",
    "                    overlap_right=overlap_right if col < num_cols - 1 else 0,\n",
    "                    overlap_top=overlap_top if row > 0 else 0,\n",
    "                    overlap_bottom=overlap_bottom if row < num_rows - 1 else 0\n",
    "                )\n",
    "                \n",
    "                segments.append(segment)\n",
    "        \n",
    "        return segments\n",
    "    \n",
    "    def extract_segment(self, image: np.ndarray, segment: Segment) -> np.ndarray:\n",
    "        \"\"\"Extract image region for a segment\"\"\"\n",
    "        return image[segment.y_start:segment.y_end, segment.x_start:segment.x_end]\n",
    "    \n",
    "    def process_segmented(self, image: np.ndarray, \n",
    "                         process_func: Callable[[np.ndarray, Dict], Dict],\n",
    "                         segment_parameters: Optional[List[Dict]] = None,\n",
    "                         segment_size: Optional[Tuple[int, int]] = None,\n",
    "                         num_segments: Optional[Tuple[int, int]] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Process image in segments and merge results\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            process_func: Function to process each segment (image, params) -> result\n",
    "            segment_parameters: Optional list of parameters for each segment\n",
    "            segment_size: Size of each segment\n",
    "            num_segments: Number of segments (rows, cols)\n",
    "            \n",
    "        Returns:\n",
    "            Merged processing results\n",
    "        \"\"\"\n",
    "        segments = self.create_segments(image.shape, segment_size, num_segments)\n",
    "        \n",
    "        if segment_parameters is None:\n",
    "            segment_parameters = [{}] * len(segments)\n",
    "        elif len(segment_parameters) < len(segments):\n",
    "            # Extend with default parameters\n",
    "            segment_parameters.extend([{}] * (len(segments) - len(segment_parameters)))\n",
    "        \n",
    "        # Process each segment\n",
    "        segment_results = []\n",
    "        for i, segment in enumerate(segments):\n",
    "            segment_image = self.extract_segment(image, segment)\n",
    "            params = segment_parameters[i] if i < len(segment_parameters) else {}\n",
    "            segment.params = params\n",
    "            \n",
    "            result = process_func(segment_image, params)\n",
    "            result['segment'] = segment\n",
    "            segment_results.append(result)\n",
    "        \n",
    "        # Merge results\n",
    "        merged_result = self._merge_segment_results(segment_results, image.shape)\n",
    "        \n",
    "        return merged_result\n",
    "    \n",
    "    def _merge_segment_results(self, segment_results: List[Dict], \n",
    "                               image_shape: Tuple[int, int]) -> Dict:\n",
    "        \"\"\"\n",
    "        Merge results from multiple segments with weighted blending in overlap zones\n",
    "        \n",
    "        Args:\n",
    "            segment_results: List of results from each segment\n",
    "            image_shape: (height, width) of full image\n",
    "            \n",
    "        Returns:\n",
    "            Merged result dictionary\n",
    "        \"\"\"\n",
    "        height, width = image_shape\n",
    "        \n",
    "        # Initialize merged arrays\n",
    "        merged_data = {}\n",
    "        weight_accumulator = {}\n",
    "        \n",
    "        for result in segment_results:\n",
    "            segment = result['segment']\n",
    "            \n",
    "            # Process each data field in result\n",
    "            for key, value in result.items():\n",
    "                if key == 'segment':\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(value, np.ndarray):\n",
    "                    # Handle array data\n",
    "                    if key not in merged_data:\n",
    "                        merged_data[key] = np.zeros(image_shape, dtype=value.dtype)\n",
    "                        weight_accumulator[key] = np.zeros(image_shape, dtype=np.float32)\n",
    "                    \n",
    "                    # Create weight mask for this segment\n",
    "                    weights = self._create_segment_weights(\n",
    "                        segment, image_shape, value.shape\n",
    "                    )\n",
    "                    \n",
    "                    # Map segment coordinates to full image coordinates\n",
    "                    seg_h, seg_w = value.shape[:2] if len(value.shape) >= 2 else (value.shape[0], 1)\n",
    "                    \n",
    "                    # Adjust for actual segment size\n",
    "                    y_start = segment.y_start\n",
    "                    y_end = min(segment.y_end, y_start + seg_h)\n",
    "                    x_start = segment.x_start\n",
    "                    x_end = min(segment.x_end, x_start + seg_w)\n",
    "                    \n",
    "                    # Extract relevant portion\n",
    "                    seg_y_end = y_end - y_start\n",
    "                    seg_x_end = x_end - x_start\n",
    "                    \n",
    "                    if len(value.shape) == 2:\n",
    "                        # 2D array\n",
    "                        seg_data = value[:seg_y_end, :seg_x_end]\n",
    "                        merged_data[key][y_start:y_end, x_start:x_end] += (\n",
    "                            seg_data * weights[y_start:y_end, x_start:x_end]\n",
    "                        )\n",
    "                        weight_accumulator[key][y_start:y_end, x_start:x_end] += (\n",
    "                            weights[y_start:y_end, x_start:x_end]\n",
    "                        )\n",
    "                    elif len(value.shape) == 1:\n",
    "                        # 1D array - handle as row or column\n",
    "                        if seg_h > seg_w:\n",
    "                            # Column vector - need to match the shape of merged_data slice\n",
    "                            seg_data = value[:seg_y_end]\n",
    "                            # Ensure seg_data matches the slice size\n",
    "                            seg_data = seg_data[:y_end - y_start]\n",
    "                            # merged_data[key][y_start:y_end, x_start] is 1D, so we add 1D\n",
    "                            merged_data[key][y_start:y_end, x_start] += (\n",
    "                                seg_data * weights[y_start:y_end, x_start]\n",
    "                            )\n",
    "                            weight_accumulator[key][y_start:y_end, x_start] += (\n",
    "                                weights[y_start:y_end, x_start]\n",
    "                            )\n",
    "                        else:\n",
    "                            # Row vector\n",
    "                            seg_data = value[:seg_x_end]\n",
    "                            seg_data = seg_data[:x_end - x_start]\n",
    "                            weight_slice = weights[y_start, x_start:x_end]\n",
    "                            merged_data[key][y_start, x_start:x_end] += (\n",
    "                                seg_data * weight_slice\n",
    "                            )\n",
    "                            weight_accumulator[key][y_start, x_start:x_end] += weight_slice\n",
    "                elif isinstance(value, (dict, list)):\n",
    "                    # Handle nested structures - collect all and merge later\n",
    "                    if key not in merged_data:\n",
    "                        merged_data[key] = []\n",
    "                    merged_data[key].append(value)\n",
    "        \n",
    "        # Normalize by weights\n",
    "        for key in merged_data:\n",
    "            if isinstance(merged_data[key], np.ndarray) and key in weight_accumulator:\n",
    "                weights = weight_accumulator[key]\n",
    "                # Avoid division by zero\n",
    "                weights = np.where(weights > 0, weights, 1.0)\n",
    "                merged_data[key] = merged_data[key] / weights\n",
    "        \n",
    "        return merged_data\n",
    "    \n",
    "    def _create_segment_weights(self, segment: Segment, \n",
    "                               image_shape: Tuple[int, int],\n",
    "                               segment_data_shape: Tuple) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create weight mask for segment with smooth transitions in overlap zones\n",
    "        \n",
    "        Args:\n",
    "            segment: Segment object\n",
    "            image_shape: Full image shape\n",
    "            segment_data_shape: Shape of segment data\n",
    "            \n",
    "        Returns:\n",
    "            Weight array matching image_shape\n",
    "        \"\"\"\n",
    "        height, width = image_shape\n",
    "        weights = np.ones((height, width), dtype=np.float32)\n",
    "        \n",
    "        # Reduce weights in overlap regions\n",
    "        y_start = segment.y_start\n",
    "        y_end = segment.y_end\n",
    "        x_start = segment.x_start\n",
    "        x_end = segment.x_end\n",
    "        \n",
    "        # Top overlap\n",
    "        if segment.overlap_top > 0:\n",
    "            overlap_region = weights[y_start:y_start + segment.overlap_top, x_start:x_end]\n",
    "            fade = np.linspace(0.5, 1.0, segment.overlap_top)\n",
    "            weights[y_start:y_start + segment.overlap_top, x_start:x_end] = (\n",
    "                fade[:, np.newaxis] * overlap_region\n",
    "            )\n",
    "        \n",
    "        # Bottom overlap\n",
    "        if segment.overlap_bottom > 0:\n",
    "            overlap_region = weights[y_end - segment.overlap_bottom:y_end, x_start:x_end]\n",
    "            fade = np.linspace(1.0, 0.5, segment.overlap_bottom)\n",
    "            weights[y_end - segment.overlap_bottom:y_end, x_start:x_end] = (\n",
    "                fade[:, np.newaxis] * overlap_region\n",
    "            )\n",
    "        \n",
    "        # Left overlap\n",
    "        if segment.overlap_left > 0:\n",
    "            overlap_region = weights[y_start:y_end, x_start:x_start + segment.overlap_left]\n",
    "            fade = np.linspace(0.5, 1.0, segment.overlap_left)\n",
    "            weights[y_start:y_end, x_start:x_start + segment.overlap_left] = (\n",
    "                fade[np.newaxis, :] * overlap_region\n",
    "            )\n",
    "        \n",
    "        # Right overlap\n",
    "        if segment.overlap_right > 0:\n",
    "            overlap_region = weights[y_start:y_end, x_end - segment.overlap_right:x_end]\n",
    "            fade = np.linspace(1.0, 0.5, segment.overlap_right)\n",
    "            weights[y_start:y_end, x_end - segment.overlap_right:x_end] = (\n",
    "                fade[np.newaxis, :] * overlap_region\n",
    "            )\n",
    "        \n",
    "        # Edge handling: full weight at image boundaries\n",
    "        if y_start == 0:\n",
    "            weights[0, :] = 1.0\n",
    "        if y_end == height:\n",
    "            weights[-1, :] = 1.0\n",
    "        if x_start == 0:\n",
    "            weights[:, 0] = 1.0\n",
    "        if x_end == width:\n",
    "            weights[:, -1] = 1.0\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def get_segment_for_point(self, x: int, y: int, segments: List[Segment]) -> Optional[Segment]:\n",
    "        \"\"\"\n",
    "        Get the segment that contains a point, prioritizing non-overlap regions\n",
    "        \n",
    "        Args:\n",
    "            x: X coordinate\n",
    "            y: Y coordinate\n",
    "            segments: List of segments\n",
    "            \n",
    "        Returns:\n",
    "            Segment containing the point, or None\n",
    "        \"\"\"\n",
    "        # First, find all segments containing the point\n",
    "        containing_segments = []\n",
    "        for seg in segments:\n",
    "            if (seg.x_start <= x < seg.x_end and \n",
    "                seg.y_start <= y < seg.y_end):\n",
    "                containing_segments.append(seg)\n",
    "        \n",
    "        if not containing_segments:\n",
    "            return None\n",
    "        \n",
    "        # If only one segment, return it\n",
    "        if len(containing_segments) == 1:\n",
    "            return containing_segments[0]\n",
    "        \n",
    "        # If multiple segments (overlap region), prefer the one where\n",
    "        # the point is NOT in the overlap zone\n",
    "        for seg in containing_segments:\n",
    "            # Check if point is in overlap zones\n",
    "            in_left_overlap = (seg.overlap_left > 0 and \n",
    "                             seg.x_start <= x < seg.x_start + seg.overlap_left)\n",
    "            in_right_overlap = (seg.overlap_right > 0 and \n",
    "                              seg.x_end - seg.overlap_right <= x < seg.x_end)\n",
    "            in_top_overlap = (seg.overlap_top > 0 and \n",
    "                            seg.y_start <= y < seg.y_start + seg.overlap_top)\n",
    "            in_bottom_overlap = (seg.overlap_bottom > 0 and \n",
    "                               seg.y_end - seg.overlap_bottom <= y < seg.y_end)\n",
    "            \n",
    "            # If not in any overlap zone, prefer this segment\n",
    "            if not (in_left_overlap or in_right_overlap or in_top_overlap or in_bottom_overlap):\n",
    "                return seg\n",
    "        \n",
    "        # If all are in overlap, return the first one\n",
    "        return containing_segments[0]\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Segmented Processing Module\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_2_segmented_processing.py\n",
    "# Purpose: Cell 2 code for Kaggle notebook - Segmented Processing\n",
    "# Usage: Copy entire file into Cell 2 of Kaggle notebook\n",
    "# Source: functions_python/segmented_processing.py\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Line Visualization Module\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_3_line_visualization.py\n",
    "# Purpose: Cell 3 code for Kaggle notebook - Line Visualization\n",
    "# Usage: Copy entire file into Cell 3 of Kaggle notebook\n",
    "# Source: functions_python/line_visualization.py\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Line Visualization Module\n",
    "Visualizes detected grid lines with polynomial equations and checks for oscillation\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import os\n",
    "\n",
    "\n",
    "class LineVisualizer:\n",
    "    \"\"\"Visualize grid lines and validate oscillation\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str = \"data/visualizations\"):\n",
    "        \"\"\"\n",
    "        Initialize visualizer\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save visualization images\n",
    "        \"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def visualize_grid_lines(self, image: np.ndarray, grid_info: Dict, \n",
    "                            filename: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Visualize detected grid lines overlaid on original image\n",
    "        \n",
    "        Args:\n",
    "            image: Original ECG image\n",
    "            grid_info: Grid detection results from GridDetector\n",
    "            filename: Optional filename for saving (without extension)\n",
    "            \n",
    "        Returns:\n",
    "            Path to saved visualization image\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0, 0].imshow(image, cmap='gray')\n",
    "        axes[0, 0].set_title('Original Image')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Horizontal lines\n",
    "        axes[0, 1].imshow(image, cmap='gray')\n",
    "        self._plot_lines(axes[0, 1], grid_info['horizontal_lines'], 'horizontal', \n",
    "                        image.shape, color='red')\n",
    "        axes[0, 1].set_title(f'Horizontal Lines ({len(grid_info[\"horizontal_lines\"])} detected)')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        # Vertical lines\n",
    "        axes[1, 0].imshow(image, cmap='gray')\n",
    "        self._plot_lines(axes[1, 0], grid_info['vertical_lines'], 'vertical',\n",
    "                        image.shape, color='blue')\n",
    "        axes[1, 0].set_title(f'Vertical Lines ({len(grid_info[\"vertical_lines\"])} detected)')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # All lines with intersections\n",
    "        axes[1, 1].imshow(image, cmap='gray')\n",
    "        self._plot_lines(axes[1, 1], grid_info['horizontal_lines'], 'horizontal',\n",
    "                        image.shape, color='red', alpha=0.6)\n",
    "        self._plot_lines(axes[1, 1], grid_info['vertical_lines'], 'vertical',\n",
    "                        image.shape, color='blue', alpha=0.6)\n",
    "        self._plot_intersections(axes[1, 1], grid_info['intersections'])\n",
    "        axes[1, 1].set_title('Grid with Intersections')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        if filename is None:\n",
    "            filename = 'grid_visualization'\n",
    "        \n",
    "        output_path = os.path.join(self.output_dir, f\"{filename}.png\")\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def _plot_lines(self, ax, lines: List[Dict], orientation: str, \n",
    "                   image_shape: Tuple[int, int], color: str = 'red', alpha: float = 1.0):\n",
    "        \"\"\"Plot polynomial lines on axes\"\"\"\n",
    "        for i, line in enumerate(lines):\n",
    "            func = line['function']\n",
    "            x_min, x_max = line['domain']\n",
    "            \n",
    "            if orientation == 'horizontal':\n",
    "                # y = f(x)\n",
    "                x_plot = np.linspace(max(0, x_min), min(image_shape[1], x_max), 200)\n",
    "                y_plot = func(x_plot)\n",
    "                \n",
    "                # Clip to image bounds\n",
    "                valid = (y_plot >= 0) & (y_plot < image_shape[0])\n",
    "                x_plot = x_plot[valid]\n",
    "                y_plot = y_plot[valid]\n",
    "                \n",
    "                ax.plot(x_plot, y_plot, color=color, linewidth=1.5, alpha=alpha,\n",
    "                       label=f\"Degree {line['degree']}\" if i == 0 else \"\")\n",
    "            else:\n",
    "                # x = f(y)\n",
    "                y_plot = np.linspace(max(0, x_min), min(image_shape[0], x_max), 200)\n",
    "                x_plot = func(y_plot)\n",
    "                \n",
    "                # Clip to image bounds\n",
    "                valid = (x_plot >= 0) & (x_plot < image_shape[1])\n",
    "                y_plot = y_plot[valid]\n",
    "                x_plot = x_plot[valid]\n",
    "                \n",
    "                ax.plot(x_plot, y_plot, color=color, linewidth=1.5, alpha=alpha,\n",
    "                       label=f\"Degree {line['degree']}\" if i == 0 else \"\")\n",
    "    \n",
    "    def _plot_intersections(self, ax, intersections: List[Dict]):\n",
    "        \"\"\"Plot grid intersections\"\"\"\n",
    "        if not intersections:\n",
    "            return\n",
    "        \n",
    "        x_coords = [int['x'] for int in intersections]\n",
    "        y_coords = [int['y'] for int in intersections]\n",
    "        \n",
    "        ax.scatter(x_coords, y_coords, c='yellow', s=20, alpha=0.7, \n",
    "                  edgecolors='black', linewidths=0.5, zorder=10)\n",
    "    \n",
    "    def compare_polynomial_degrees(self, image: np.ndarray, grid_info: Dict,\n",
    "                                   line_idx: int = 0, orientation: str = 'horizontal',\n",
    "                                   filename: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Compare different polynomial degrees for a single line\n",
    "        \n",
    "        Args:\n",
    "            image: Original ECG image\n",
    "            grid_info: Grid detection results\n",
    "            line_idx: Index of line to compare\n",
    "            orientation: 'horizontal' or 'vertical'\n",
    "            filename: Optional filename for saving\n",
    "            \n",
    "        Returns:\n",
    "            Path to saved comparison image\n",
    "        \"\"\"\n",
    "        lines = grid_info[f'{orientation}_lines']\n",
    "        if line_idx >= len(lines):\n",
    "            raise ValueError(f\"Line index {line_idx} out of range\")\n",
    "        \n",
    "        line = lines[line_idx]\n",
    "        func = line['function']\n",
    "        x_min, x_max = line['domain']\n",
    "        \n",
    "        # Sample points along the line\n",
    "        if orientation == 'horizontal':\n",
    "            x_samples = np.linspace(x_min, x_max, 100)\n",
    "            y_samples = func(x_samples)\n",
    "            \n",
    "            # Fit different degrees\n",
    "            degrees_to_compare = [1, 2, 3]\n",
    "            fits = {}\n",
    "            for deg in degrees_to_compare:\n",
    "                if deg <= len(x_samples) - 1:\n",
    "                    coeffs = np.polyfit(x_samples, y_samples, deg)\n",
    "                    fits[deg] = np.poly1d(coeffs)\n",
    "        else:\n",
    "            y_samples = np.linspace(x_min, x_max, 100)\n",
    "            x_samples = func(y_samples)\n",
    "            \n",
    "            degrees_to_compare = [1, 2, 3]\n",
    "            fits = {}\n",
    "            for deg in degrees_to_compare:\n",
    "                if deg <= len(y_samples) - 1:\n",
    "                    coeffs = np.polyfit(y_samples, x_samples, deg)\n",
    "                    fits[deg] = np.poly1d(coeffs)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Original image with line\n",
    "        axes[0].imshow(image, cmap='gray')\n",
    "        if orientation == 'horizontal':\n",
    "            x_plot = np.linspace(x_min, x_max, 200)\n",
    "            y_plot = func(x_plot)\n",
    "            axes[0].plot(x_plot, y_plot, 'r-', linewidth=2, label=f\"Detected (degree {line['degree']})\")\n",
    "        else:\n",
    "            y_plot = np.linspace(x_min, x_max, 200)\n",
    "            x_plot = func(y_plot)\n",
    "            axes[0].plot(x_plot, y_plot, 'r-', linewidth=2, label=f\"Detected (degree {line['degree']})\")\n",
    "        axes[0].set_title(f'{orientation.capitalize()} Line Comparison')\n",
    "        axes[0].axis('off')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Comparison plot\n",
    "        if orientation == 'horizontal':\n",
    "            x_plot = np.linspace(x_min, x_max, 200)\n",
    "            axes[1].plot(x_samples, y_samples, 'ko', markersize=3, label='Sample points')\n",
    "            for deg, fit_func in fits.items():\n",
    "                y_fit = fit_func(x_plot)\n",
    "                axes[1].plot(x_plot, y_fit, linewidth=2, label=f'Degree {deg}')\n",
    "            axes[1].set_xlabel('X coordinate')\n",
    "            axes[1].set_ylabel('Y coordinate')\n",
    "        else:\n",
    "            y_plot = np.linspace(x_min, x_max, 200)\n",
    "            axes[1].plot(x_samples, y_samples, 'ko', markersize=3, label='Sample points')\n",
    "            for deg, fit_func in fits.items():\n",
    "                x_fit = fit_func(y_plot)\n",
    "                axes[1].plot(x_fit, y_plot, linewidth=2, label=f'Degree {deg}')\n",
    "            axes[1].set_xlabel('X coordinate')\n",
    "            axes[1].set_ylabel('Y coordinate')\n",
    "        \n",
    "        axes[1].set_title('Polynomial Fit Comparison')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if filename is None:\n",
    "            filename = f'polynomial_comparison_{orientation}_{line_idx}'\n",
    "        \n",
    "        output_path = os.path.join(self.output_dir, f\"{filename}.png\")\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def check_oscillation(self, grid_info: Dict, threshold: float = 5.0) -> Dict:\n",
    "        \"\"\"\n",
    "        Check for oscillation in higher-order lines\n",
    "        \n",
    "        Args:\n",
    "            grid_info: Grid detection results\n",
    "            threshold: Maximum allowed deviation from linear fit (pixels)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with oscillation analysis results\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'horizontal_lines': [],\n",
    "            'vertical_lines': [],\n",
    "            'total_checked': 0,\n",
    "            'oscillating_lines': 0\n",
    "        }\n",
    "        \n",
    "        # Check horizontal lines\n",
    "        for i, line in enumerate(grid_info['horizontal_lines']):\n",
    "            if line['degree'] > 1:\n",
    "                deviation = self._calculate_linear_deviation(line, 'horizontal', \n",
    "                                                             grid_info['image_shape'])\n",
    "                is_oscillating = deviation > threshold\n",
    "                results['horizontal_lines'].append({\n",
    "                    'index': i,\n",
    "                    'degree': line['degree'],\n",
    "                    'max_deviation': deviation,\n",
    "                    'oscillating': is_oscillating\n",
    "                })\n",
    "                results['total_checked'] += 1\n",
    "                if is_oscillating:\n",
    "                    results['oscillating_lines'] += 1\n",
    "        \n",
    "        # Check vertical lines\n",
    "        for i, line in enumerate(grid_info['vertical_lines']):\n",
    "            if line['degree'] > 1:\n",
    "                deviation = self._calculate_linear_deviation(line, 'vertical',\n",
    "                                                           grid_info['image_shape'])\n",
    "                is_oscillating = deviation > threshold\n",
    "                results['vertical_lines'].append({\n",
    "                    'index': i,\n",
    "                    'degree': line['degree'],\n",
    "                    'max_deviation': deviation,\n",
    "                    'oscillating': is_oscillating\n",
    "                })\n",
    "                results['total_checked'] += 1\n",
    "                if is_oscillating:\n",
    "                    results['oscillating_lines'] += 1\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_linear_deviation(self, line: Dict, orientation: str,\n",
    "                                   image_shape: Tuple[int, int]) -> float:\n",
    "        \"\"\"Calculate maximum deviation from linear fit\"\"\"\n",
    "        func = line['function']\n",
    "        x_min, x_max = line['domain']\n",
    "        \n",
    "        # Sample points\n",
    "        num_samples = 100\n",
    "        if orientation == 'horizontal':\n",
    "            x_samples = np.linspace(x_min, x_max, num_samples)\n",
    "            y_poly = func(x_samples)\n",
    "            \n",
    "            # Fit linear\n",
    "            coeffs_linear = np.polyfit(x_samples, y_poly, 1)\n",
    "            y_linear = np.polyval(coeffs_linear, x_samples)\n",
    "            \n",
    "            # Calculate deviation\n",
    "            deviation = np.max(np.abs(y_poly - y_linear))\n",
    "        else:\n",
    "            y_samples = np.linspace(x_min, x_max, num_samples)\n",
    "            x_poly = func(y_samples)\n",
    "            \n",
    "            # Fit linear\n",
    "            coeffs_linear = np.polyfit(y_samples, x_poly, 1)\n",
    "            x_linear = np.polyval(coeffs_linear, y_samples)\n",
    "            \n",
    "            # Calculate deviation\n",
    "            deviation = np.max(np.abs(x_poly - x_linear))\n",
    "        \n",
    "        return float(deviation)\n",
    "    \n",
    "    def generate_oscillation_report(self, oscillation_results: Dict, \n",
    "                                   filename: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate a text report of oscillation analysis\n",
    "        \n",
    "        Args:\n",
    "            oscillation_results: Results from check_oscillation()\n",
    "            filename: Optional filename for saving\n",
    "            \n",
    "        Returns:\n",
    "            Path to saved report\n",
    "        \"\"\"\n",
    "        report_lines = [\n",
    "            \"Grid Line Oscillation Analysis Report\",\n",
    "            \"=\" * 50,\n",
    "            \"\",\n",
    "            f\"Total lines checked: {oscillation_results['total_checked']}\",\n",
    "            f\"Oscillating lines: {oscillation_results['oscillating_lines']}\",\n",
    "            \"\",\n",
    "            \"Horizontal Lines:\",\n",
    "            \"-\" * 30\n",
    "        ]\n",
    "        \n",
    "        for line_info in oscillation_results['horizontal_lines']:\n",
    "            status = \"OSCILLATING\" if line_info['oscillating'] else \"OK\"\n",
    "            report_lines.append(\n",
    "                f\"  Line {line_info['index']}: Degree {line_info['degree']}, \"\n",
    "                f\"Max deviation: {line_info['max_deviation']:.2f} px - {status}\"\n",
    "            )\n",
    "        \n",
    "        report_lines.extend([\n",
    "            \"\",\n",
    "            \"Vertical Lines:\",\n",
    "            \"-\" * 30\n",
    "        ])\n",
    "        \n",
    "        for line_info in oscillation_results['vertical_lines']:\n",
    "            status = \"OSCILLATING\" if line_info['oscillating'] else \"OK\"\n",
    "            report_lines.append(\n",
    "                f\"  Line {line_info['index']}: Degree {line_info['degree']}, \"\n",
    "                f\"Max deviation: {line_info['max_deviation']:.2f} px - {status}\"\n",
    "            )\n",
    "        \n",
    "        report_text = \"\\n\".join(report_lines)\n",
    "        \n",
    "        if filename is None:\n",
    "            filename = 'oscillation_report'\n",
    "        \n",
    "        output_path = os.path.join(self.output_dir, f\"{filename}.txt\")\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Line Visualization Module\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_3_line_visualization.py\n",
    "# Purpose: Cell 3 code for Kaggle notebook - Line Visualization\n",
    "# Usage: Copy entire file into Cell 3 of Kaggle notebook\n",
    "# Source: functions_python/line_visualization.py\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ECG Image Digitization Pipeline\n",
    "Core processing modules for converting ECG images to time-series data\n",
    "\n",
    "This can be deployed as:\n",
    "1. Python Cloud Function (using functions-framework)\n",
    "2. Docker container on Cloud Run\n",
    "3. Local processing with Firebase Admin SDK\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 4: Loading digitization_pipeline.py\")\n",
    "print(\"=\" * 70)\n",
    "print(\"File: functions_python/digitization_pipeline.py\")\n",
    "print(\"Status: Starting...\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "\n",
    "# STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "\n",
    "# Import classes from previous cells (they're in global namespace, not modules)\n",
    "# Try to get from global namespace first (from previous cells)\n",
    "# Then fall back to module import (if files were uploaded)\n",
    "\n",
    "print(\"\\n[Step 4.1] Loading GridDetector...\")\n",
    "try:\n",
    "    # First try: Get from global namespace (Cell 1)\n",
    "    if 'GridDetector' in globals():\n",
    "        GridDetector = globals()['GridDetector']\n",
    "        print(\"   Success: Loaded GridDetector from Cell 1 (grid_detection.py)\")\n",
    "    else:\n",
    "        # Second try: Import as module (if file was uploaded)\n",
    "        from grid_detection import GridDetector\n",
    "        print(\"   Success: Imported GridDetector from grid_detection module\")\n",
    "except Exception as e:\n",
    "    print(f\"   ERROR: Could not load GridDetector: {e}\")\n",
    "    print(\"   Make sure Cell 1 (grid_detection.py) ran successfully!\")\n",
    "    print(\"   Check that you see 'STEP 1: ... SUCCESS' message from Cell 1\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n[Step 4.2] Loading SegmentedProcessor...\")\n",
    "try:\n",
    "    if 'SegmentedProcessor' in globals():\n",
    "        SegmentedProcessor = globals()['SegmentedProcessor']\n",
    "        print(\"   Success: Loaded SegmentedProcessor from Cell 2 (segmented_processing.py)\")\n",
    "    else:\n",
    "        from segmented_processing import SegmentedProcessor\n",
    "        print(\"   Success: Imported SegmentedProcessor from segmented_processing module\")\n",
    "except Exception as e:\n",
    "    print(f\"   ERROR: Could not load SegmentedProcessor: {e}\")\n",
    "    print(\"   Make sure Cell 2 (segmented_processing.py) ran successfully!\")\n",
    "    print(\"   Check that you see 'STEP 2: ... SUCCESS' message from Cell 2\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n[Step 4.3] Loading LineVisualizer...\")\n",
    "try:\n",
    "    if 'LineVisualizer' in globals():\n",
    "        LineVisualizer = globals()['LineVisualizer']\n",
    "        print(\"   Success: Loaded LineVisualizer from Cell 3 (line_visualization.py)\")\n",
    "    else:\n",
    "        from line_visualization import LineVisualizer\n",
    "        print(\"   Success: Imported LineVisualizer from line_visualization module\")\n",
    "except Exception as e:\n",
    "    print(f\"   ERROR: Could not load LineVisualizer: {e}\")\n",
    "    print(\"   Make sure Cell 3 (line_visualization.py) ran successfully!\")\n",
    "    print(\"   Check that you see 'STEP 3: ... SUCCESS' message from Cell 3\")\n",
    "    raise\n",
    "\n",
    "# STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: All dependencies loaded successfully!\")\n",
    "print(\"File: functions_python/digitization_pipeline.py\")\n",
    "print(\"Status: Loading ECGDigitizer class...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "class ECGDigitizer:\n",
    "    \"\"\"Main class for ECG image digitization\"\"\"\n",
    "    \n",
    "    def __init__(self, use_segmented_processing: bool = True, \n",
    "                 enable_visualization: bool = False):\n",
    "        self.lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "        self.sampling_rate = 500  # Hz\n",
    "        self.grid_spacing_mm = 1.0  # mm per small square\n",
    "        self.voltage_scale = 0.1  # mV per mm (standard ECG)\n",
    "        self.time_scale = 0.04  # seconds per mm (25 mm/s standard)\n",
    "        \n",
    "        # Initialize new modules\n",
    "        self.grid_detector = GridDetector(max_polynomial_degree=3)\n",
    "        self.segmented_processor = SegmentedProcessor(overlap_ratio=0.2) if use_segmented_processing else None\n",
    "        self.visualizer = LineVisualizer() if enable_visualization else None\n",
    "        self.use_segmented = use_segmented_processing\n",
    "        \n",
    "    def process_image(self, image_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Main processing pipeline\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to ECG image file\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing extracted time-series data and metadata\n",
    "        \"\"\"\n",
    "        # Step 1: Load and preprocess image\n",
    "        image = self.load_image(image_path)\n",
    "        preprocessed = self.preprocess_image(image)\n",
    "        \n",
    "        # Step 2: Detect grid and calibrate (using enhanced grid detection)\n",
    "        grid_info = self.detect_grid(preprocessed)\n",
    "        self.last_grid_info = grid_info  # Store for quality assessment\n",
    "        \n",
    "        # Visualize if enabled\n",
    "        if self.visualizer:\n",
    "            self.visualizer.visualize_grid_lines(image, grid_info, \n",
    "                                                filename=f\"grid_{image_path.split('/')[-1]}\")\n",
    "        \n",
    "        calibration = self.calibrate_scales(grid_info)\n",
    "        \n",
    "        # Step 3: Detect and extract leads\n",
    "        lead_regions = self.detect_leads(preprocessed, grid_info)\n",
    "        \n",
    "        # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "        \n",
    "        # Step 4: Extract signals from each lead\n",
    "        signals = {}\n",
    "        for lead_name, region in lead_regions.items():\n",
    "            signal_data = self.extract_signal(region, calibration)\n",
    "            signals[lead_name] = signal_data\n",
    "            \n",
    "        # Step 5: Post-process signals\n",
    "        processed_signals = self.post_process_signals(signals)\n",
    "        \n",
    "        # Step 6: Calculate quality metrics\n",
    "        quality = self.calculate_quality_metrics(processed_signals)\n",
    "        \n",
    "        return {\n",
    "            'leads': processed_signals,\n",
    "            'metadata': {\n",
    "                'sampling_rate': self.sampling_rate,\n",
    "                'calibration': calibration,\n",
    "                'quality': quality\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def load_image(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Load and convert image to grayscale\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "            \n",
    "        return gray\n",
    "    \n",
    "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Preprocess image: denoise, enhance contrast, correct rotation\n",
    "        \"\"\"\n",
    "        # 1. Denoise\n",
    "        denoised = cv2.fastNlMeansDenoising(image, None, 10, 7, 21)\n",
    "        \n",
    "        # 2. Enhance contrast using CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(denoised)\n",
    "        \n",
    "        # 3. Detect and correct rotation\n",
    "        rotated = self.correct_rotation(enhanced)\n",
    "        \n",
    "        # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "        \n",
    "        # 4. Binarize (threshold)\n",
    "        _, binary = cv2.threshold(rotated, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        return binary\n",
    "    \n",
    "    def correct_rotation(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Detect and correct image rotation using Hough line detection\"\"\"\n",
    "        edges = cv2.Canny(image, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "        \n",
    "        if lines is None:\n",
    "            return image\n",
    "        \n",
    "        # Calculate dominant angle\n",
    "        angles = []\n",
    "        for line in lines[:20]:  # Use top 20 lines\n",
    "            rho, theta = line[0]\n",
    "            angle = np.degrees(theta) - 90\n",
    "            if abs(angle) < 45:  # Only consider small rotations\n",
    "                angles.append(angle)\n",
    "        \n",
    "        if not angles:\n",
    "            return image\n",
    "        \n",
    "        # Use median angle to avoid outliers\n",
    "        rotation_angle = np.median(angles)\n",
    "        \n",
    "        # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "        \n",
    "        # Rotate image\n",
    "        (h, w) = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h), \n",
    "                                 flags=cv2.INTER_CUBIC,\n",
    "                                 borderMode=cv2.BORDER_REPLICATE)\n",
    "        \n",
    "        return rotated\n",
    "    \n",
    "    def detect_grid(self, image: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect ECG grid lines using enhanced polynomial grid detection\n",
    "        \n",
    "        Args:\n",
    "            image: Preprocessed binary image\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing grid information\n",
    "        \"\"\"\n",
    "        if self.use_segmented and self.segmented_processor:\n",
    "            # Use segmented processing for grid detection\n",
    "            def process_segment(seg_image, params):\n",
    "                return self.grid_detector.detect_grid(seg_image)\n",
    "            \n",
    "            # Process in segments and merge\n",
    "            segment_results = self.segmented_processor.process_segmented(\n",
    "                image, process_segment\n",
    "            )\n",
    "            \n",
    "            # Merge grid information from segments\n",
    "            # For now, use the first segment's result (can be enhanced)\n",
    "            if segment_results and 'horizontal_lines' in segment_results:\n",
    "                grid_info = {\n",
    "                    'horizontal_lines': segment_results.get('horizontal_lines', []),\n",
    "                    'vertical_lines': segment_results.get('vertical_lines', []),\n",
    "                    'intersections': segment_results.get('intersections', []),\n",
    "                    'horizontal_spacing': segment_results.get('horizontal_spacing', 10.0),\n",
    "                    'vertical_spacing': segment_results.get('vertical_spacing', 10.0),\n",
    "                    'image_shape': image.shape\n",
    "                }\n",
    "            else:\n",
    "                # Fallback to non-segmented detection\n",
    "                grid_info = self.grid_detector.detect_grid(image)\n",
    "        else:\n",
    "            # Use standard grid detection\n",
    "            grid_info = self.grid_detector.detect_grid(image)\n",
    "        \n",
    "        return grid_info\n",
    "    \n",
    "    # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "    \n",
    "    def calibrate_scales(self, grid_info: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Calibrate voltage and time scales based on grid intersections\n",
    "        \n",
    "        Standard ECG:\n",
    "        - Small square: 1mm x 1mm\n",
    "        - Large square: 5mm x 5mm\n",
    "        - Voltage: 1mm = 0.1 mV\n",
    "        - Time: 1mm = 0.04s (at 25mm/s)\n",
    "        \"\"\"\n",
    "        # Use intersection-based calibration if available\n",
    "        if 'intersections' in grid_info and len(grid_info['intersections']) > 1:\n",
    "            # Calculate spacing from intersections\n",
    "            intersections = grid_info['intersections']\n",
    "            \n",
    "            # Safely extract coordinates from intersections\n",
    "            # Handle both dict and list formats\n",
    "            try:\n",
    "                y_coords = []\n",
    "                x_coords = []\n",
    "                \n",
    "                for item in intersections:\n",
    "                    if isinstance(item, dict):\n",
    "                        # Dictionary format: {'x': ..., 'y': ...}\n",
    "                        # Handle nested dicts or direct values\n",
    "                        x_val = item.get('x')\n",
    "                        y_val = item.get('y')\n",
    "                        \n",
    "                        # If values are dicts, try to extract numeric values\n",
    "                        if isinstance(x_val, dict):\n",
    "                            # Try common keys\n",
    "                            x_val = x_val.get('value') or x_val.get('coord') or x_val.get('x')\n",
    "                        if isinstance(y_val, dict):\n",
    "                            y_val = y_val.get('value') or y_val.get('coord') or y_val.get('y')\n",
    "                        \n",
    "                        # Convert to float if possible\n",
    "                        try:\n",
    "                            if x_val is not None and y_val is not None:\n",
    "                                x_coords.append(float(x_val))\n",
    "                                y_coords.append(float(y_val))\n",
    "                        except (ValueError, TypeError):\n",
    "                            continue  # Skip this intersection if conversion fails\n",
    "                    elif isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                        # List/tuple format: [x, y] or (x, y)\n",
    "                        try:\n",
    "                            x_coords.append(float(item[0]))\n",
    "                            y_coords.append(float(item[1]))\n",
    "                        except (ValueError, TypeError):\n",
    "                            continue  # Skip this intersection if conversion fails\n",
    "                \n",
    "                # Group intersections by approximate grid position\n",
    "                # For horizontal spacing, look at y-coordinates\n",
    "                if len(y_coords) > 1:\n",
    "                    y_coords = sorted(y_coords)\n",
    "                    v_spacings = np.diff(y_coords)\n",
    "                    v_spacing = float(np.median(v_spacings[v_spacings > 0]))\n",
    "                else:\n",
    "                    v_spacing = grid_info.get('vertical_spacing', 10.0)\n",
    "                \n",
    "                # For vertical spacing, look at x-coordinates\n",
    "                if len(x_coords) > 1:\n",
    "                    x_coords = sorted(x_coords)\n",
    "                    h_spacings = np.diff(x_coords)\n",
    "                    h_spacing = float(np.median(h_spacings[h_spacings > 0]))\n",
    "                else:\n",
    "                    h_spacing = grid_info.get('horizontal_spacing', 10.0)\n",
    "            except (KeyError, IndexError, TypeError, ValueError) as e:\n",
    "                # Fallback to spacing-based calibration if intersection parsing fails\n",
    "                print(f\"Warning: Could not parse intersections: {e}. Using spacing-based calibration.\")\n",
    "                h_spacing = grid_info.get('horizontal_spacing', 10.0)\n",
    "                v_spacing = grid_info.get('vertical_spacing', 10.0)\n",
    "        else:\n",
    "            # Fallback to spacing-based calibration\n",
    "            h_spacing = grid_info.get('horizontal_spacing', 10.0)\n",
    "            v_spacing = grid_info.get('vertical_spacing', 10.0)\n",
    "        \n",
    "        # Assume spacing is for small squares (1mm)\n",
    "        pixels_per_mm_x = h_spacing\n",
    "        pixels_per_mm_y = v_spacing\n",
    "        \n",
    "        # Calculate scale factors\n",
    "        pixels_per_mv = pixels_per_mm_y / self.voltage_scale\n",
    "        pixels_per_sec = pixels_per_mm_x / self.time_scale\n",
    "        \n",
    "        return {\n",
    "            'pixels_per_mv': pixels_per_mv,\n",
    "            'pixels_per_sec': pixels_per_sec,\n",
    "            'pixels_per_mm_x': pixels_per_mm_x,\n",
    "            'pixels_per_mm_y': pixels_per_mm_y,\n",
    "            'grid_spacing_h': h_spacing,\n",
    "            'grid_spacing_v': v_spacing\n",
    "        }\n",
    "    \n",
    "    # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "    \n",
    "    def detect_leads(self, image: np.ndarray, grid_info: Dict) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Detect the 12 lead regions in the ECG image\n",
    "        \n",
    "        Standard 12-lead layout:\n",
    "        - Usually arranged in 3-4 columns\n",
    "        - Each lead typically 2.5 seconds long\n",
    "        \"\"\"\n",
    "        height, width = image.shape\n",
    "        \n",
    "        # Standard layout: 3 columns x 4 rows + 1 long rhythm strip\n",
    "        # This is a simplified detection - actual implementation should be more robust\n",
    "        \n",
    "        lead_regions = {}\n",
    "        \n",
    "        # Divide into approximate regions (this needs to be improved with actual detection)\n",
    "        col_width = width // 3\n",
    "        row_height = height // 5\n",
    "        \n",
    "        lead_positions = [\n",
    "            ('I', 0, 0), ('aVR', 1, 0), ('V1', 2, 0),\n",
    "            ('II', 0, 1), ('aVL', 1, 1), ('V2', 2, 1),\n",
    "            ('III', 0, 2), ('aVF', 1, 2), ('V3', 2, 2),\n",
    "            ('V4', 0, 3), ('V5', 1, 3), ('V6', 2, 3),\n",
    "        ]\n",
    "        \n",
    "        for lead_name, col, row in lead_positions:\n",
    "            x1 = col * col_width\n",
    "            x2 = (col + 1) * col_width\n",
    "            y1 = row * row_height\n",
    "            y2 = (row + 1) * row_height\n",
    "            \n",
    "            region = image[y1:y2, x1:x2]\n",
    "            lead_regions[lead_name] = region\n",
    "        \n",
    "        return lead_regions\n",
    "    \n",
    "    # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "    \n",
    "    def extract_signal(self, region: np.ndarray, calibration: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract time-series signal from a lead region\n",
    "        Uses grid intersections for alignment if available\n",
    "        \n",
    "        Method: For each column (time point), find the darkest pixels (signal path)\n",
    "        \"\"\"\n",
    "        height, width = region.shape\n",
    "        signal_values = []\n",
    "        \n",
    "        # Use segmented processing if enabled and region is large enough\n",
    "        if self.use_segmented and self.segmented_processor and width > 200:\n",
    "            def extract_segment_signal(seg_image, params):\n",
    "                seg_h, seg_w = seg_image.shape\n",
    "                seg_signal = []\n",
    "                \n",
    "                for col in range(seg_w):\n",
    "                    column = seg_image[:, col]\n",
    "                    \n",
    "                    # Find signal position\n",
    "                    if np.mean(column) > 128:\n",
    "                        column = 255 - column\n",
    "                    \n",
    "                    threshold = np.max(column) * 0.5\n",
    "                    dark_pixels = column > threshold\n",
    "                    \n",
    "                    if np.any(dark_pixels):\n",
    "                        positions = np.where(dark_pixels)[0]\n",
    "                        weights = column[dark_pixels]\n",
    "                        center = np.average(positions, weights=weights)\n",
    "                    else:\n",
    "                        center = seg_h / 2\n",
    "                    \n",
    "                    voltage_pixels = seg_h / 2 - center\n",
    "                    voltage_mv = voltage_pixels / calibration['pixels_per_mv']\n",
    "                    seg_signal.append(voltage_mv)\n",
    "                \n",
    "                return {'signal': np.array(seg_signal)}\n",
    "            \n",
    "            result = self.segmented_processor.process_segmented(\n",
    "                region, extract_segment_signal, num_segments=(1, max(1, width // 150))\n",
    "            )\n",
    "            \n",
    "            if 'signal' in result:\n",
    "                signal_array = result['signal']\n",
    "            else:\n",
    "                # Fallback to standard extraction\n",
    "                signal_array = self._extract_signal_standard(region, calibration)\n",
    "        else:\n",
    "            signal_array = self._extract_signal_standard(region, calibration)\n",
    "        \n",
    "        # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "        \n",
    "        # Resample to standard sampling rate (500 Hz)\n",
    "        duration_sec = width / calibration['pixels_per_sec']\n",
    "        target_samples = int(duration_sec * self.sampling_rate)\n",
    "        \n",
    "        if len(signal_array) > 1:\n",
    "            resampled = signal.resample(signal_array, target_samples)\n",
    "        else:\n",
    "            resampled = signal_array\n",
    "        \n",
    "        return resampled\n",
    "    \n",
    "    def _extract_signal_standard(self, region: np.ndarray, calibration: Dict) -> np.ndarray:\n",
    "        \"\"\"Standard signal extraction method\"\"\"\n",
    "        height, width = region.shape\n",
    "        signal_values = []\n",
    "        \n",
    "        for col in range(width):\n",
    "            column = region[:, col]\n",
    "            \n",
    "            # Find signal position (darkest pixels)\n",
    "            if np.mean(column) > 128:  # Light background\n",
    "                column = 255 - column\n",
    "            \n",
    "            # Find weighted center of dark pixels\n",
    "            threshold = np.max(column) * 0.5\n",
    "            dark_pixels = column > threshold\n",
    "            \n",
    "            if np.any(dark_pixels):\n",
    "                positions = np.where(dark_pixels)[0]\n",
    "                weights = column[dark_pixels]\n",
    "                center = np.average(positions, weights=weights)\n",
    "            else:\n",
    "                center = height / 2  # Default to middle\n",
    "            \n",
    "            # Convert pixel position to voltage\n",
    "            voltage_pixels = height / 2 - center\n",
    "            voltage_mv = voltage_pixels / calibration['pixels_per_mv']\n",
    "            \n",
    "            signal_values.append(voltage_mv)\n",
    "        \n",
    "        return np.array(signal_values)\n",
    "    \n",
    "    def post_process_signals(self, signals: Dict[str, np.ndarray]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Post-process extracted signals:\n",
    "        - Remove baseline wander\n",
    "        - Filter noise\n",
    "        - Align signals\n",
    "        \"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for lead_name, sig in signals.items():\n",
    "            # 1. Remove baseline wander (high-pass filter at 0.5 Hz)\n",
    "            sos = signal.butter(3, 0.5, btype='high', fs=self.sampling_rate, output='sos')\n",
    "            sig_highpass = signal.sosfilt(sos, sig)\n",
    "            \n",
    "            # 2. Remove high-frequency noise (low-pass filter at 100 Hz)\n",
    "            sos = signal.butter(3, 100, btype='low', fs=self.sampling_rate, output='sos')\n",
    "            sig_filtered = signal.sosfilt(sos, sig_highpass)\n",
    "            \n",
    "            # 3. Remove powerline interference (50/60 Hz notch filter)\n",
    "            for freq in [50, 60]:\n",
    "                b, a = signal.iirnotch(freq, 30, self.sampling_rate)\n",
    "                sig_filtered = signal.filtfilt(b, a, sig_filtered)\n",
    "            \n",
    "            # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "            \n",
    "            processed.append({\n",
    "                'name': lead_name,\n",
    "                'values': sig_filtered.tolist(),\n",
    "                'sampling_rate': self.sampling_rate,\n",
    "                'duration': len(sig_filtered) / self.sampling_rate\n",
    "            })\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    # STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "    \n",
    "    def calculate_quality_metrics(self, processed_signals: List[Dict]) -> Dict:\n",
    "        \"\"\"Calculate signal quality metrics\"\"\"\n",
    "        snr_values = []\n",
    "        \n",
    "        for lead_data in processed_signals:\n",
    "            sig = np.array(lead_data['values'])\n",
    "            \n",
    "            # Estimate SNR (simplified)\n",
    "            signal_power = np.mean(sig ** 2)\n",
    "            \n",
    "            # Estimate noise from high-frequency components\n",
    "            sos = signal.butter(3, [40, 100], btype='band', fs=self.sampling_rate, output='sos')\n",
    "            noise = signal.sosfilt(sos, sig)\n",
    "            noise_power = np.mean(noise ** 2)\n",
    "            \n",
    "            if noise_power > 0:\n",
    "                snr = 10 * np.log10(signal_power / noise_power)\n",
    "            else:\n",
    "                snr = 60  # Very high SNR\n",
    "            \n",
    "            snr_values.append(snr)\n",
    "        \n",
    "        return {\n",
    "            'mean_snr': float(np.mean(snr_values)),\n",
    "            'min_snr': float(np.min(snr_values)),\n",
    "            'lead_snrs': {lead['name']: snr for lead, snr in zip(processed_signals, snr_values)}\n",
    "        }\n",
    "\n",
    "\n",
    "def process_ecg_for_firebase(image_bytes: bytes) -> Dict:\n",
    "    \"\"\"\n",
    "    Wrapper function for Firebase Cloud Function\n",
    "    \n",
    "    Args:\n",
    "        image_bytes: Image file as bytes\n",
    "        \n",
    "    Returns:\n",
    "        Processed ECG data as dictionary\n",
    "    \"\"\"\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    # Save bytes to temporary file\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_file:\n",
    "        tmp_file.write(image_bytes)\n",
    "        tmp_path = tmp_file.name\n",
    "    \n",
    "    try:\n",
    "        digitizer = ECGDigitizer()\n",
    "        result = digitizer.process_image(tmp_path)\n",
    "        return result\n",
    "    finally:\n",
    "        os.unlink(tmp_path)\n",
    "\n",
    "# STEP 4: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 4: digitization_pipeline.py loaded successfully!\")\n",
    "print(\"File: functions_python/digitization_pipeline.py\")\n",
    "print(\"Status:  SUCCESS\")\n",
    "print(\"Class: ECGDigitizer is now available\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# FILE IDENTIFICATION\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_4_ready_to_paste.py\n",
    "# Source: KAGGLE_CELL_4_READY_TO_PASTE.py\n",
    "# Purpose: Complete Cell 4 code for Kaggle notebook with fixed imports\n",
    "# Usage: Copy entire file into Cell 4 of Kaggle notebook\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 5: Submission Code for Kaggle Notebook\n",
    "\n",
    "Copy this ENTIRE file into Cell 5 of your Kaggle notebook.\n",
    "IMPORTANT: Make sure Cells 1-4 have been run successfully first!\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 5: Loading submission code\")\n",
    "print(\"=\" * 70)\n",
    "print(\"File: kaggle_notebook_complete.py\")\n",
    "print(\"Status: Starting...\")\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Import ECGDigitizer from previous cells (it's in global namespace, not a module)\n",
    "print(\"\\n[Step 5.1] Loading ECGDigitizer...\")\n",
    "try:\n",
    "    # First try: Get from global namespace (Cell 4)\n",
    "    if 'ECGDigitizer' in globals():\n",
    "        ECGDigitizer = globals()['ECGDigitizer']\n",
    "        print(\"   Success: Loaded ECGDigitizer from Cell 4 (digitization_pipeline.py)\")\n",
    "    else:\n",
    "        # Second try: Import as module (if file was uploaded)\n",
    "        from digitization_pipeline import ECGDigitizer\n",
    "        print(\"   Success: Imported ECGDigitizer from digitization_pipeline module\")\n",
    "except Exception as e:\n",
    "    print(f\"   ERROR: Could not load ECGDigitizer: {e}\")\n",
    "    print(\"   Make sure Cell 4 (digitization_pipeline.py) ran successfully!\")\n",
    "    print(\"   Check that you see 'STEP 4: ... SUCCESS' message from Cell 4\")\n",
    "    print(\"\\n  Troubleshooting:\")\n",
    "    print(\"    1. Run Cells 1-4 in order first\")\n",
    "    print(\"    2. Make sure Cell 4 completed without errors\")\n",
    "    print(\"    3. Verify you see 'STEP 4:  SUCCESS' in Cell 4 output\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: ECGDigitizer loaded successfully!\")\n",
    "print(\"Status: Ready to process images...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# STEP 5: kaggle_cell_5_complete.py\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "COMPETITION_NAME = \"physionet-ecg-image-digitization\"\n",
    "INPUT_DIR = Path('/kaggle/input') / COMPETITION_NAME\n",
    "TEST_DIR = INPUT_DIR / 'test'\n",
    "OUTPUT_DIR = Path('/kaggle/working')\n",
    "\n",
    "# IMPORTANT: submission.csv MUST be created in /kaggle/working/\n",
    "# This is the only writable directory in Kaggle notebooks\n",
    "\n",
    "LEAD_NAMES = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "SAMPLES_PER_LEAD = 5000\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "def extract_record_id(image_path: Path) -> str:\n",
    "    \"\"\"Extract record ID from filename\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'(\\d+)', image_path.stem)\n",
    "    return match.group(1) if match else image_path.stem\n",
    "\n",
    "def find_test_images() -> list:\n",
    "    \"\"\"Find all test images\"\"\"\n",
    "    images = []\n",
    "    if not TEST_DIR.exists():\n",
    "        print(f\" Test directory not found: {TEST_DIR}\")\n",
    "        return images\n",
    "    \n",
    "    for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.JPG', '.JPEG', '.PNG']:\n",
    "        images.extend(TEST_DIR.glob(f'*{ext}'))\n",
    "    \n",
    "    return sorted(images)\n",
    "\n",
    "# STEP 5: kaggle_cell_5_complete.py\n",
    "\n",
    "def process_image(image_path: Path) -> dict:\n",
    "    \"\"\"Process a single ECG image\"\"\"\n",
    "    record_id = extract_record_id(image_path)\n",
    "    print(f\"\\nProcessing: {image_path.name}\")\n",
    "    print(f\"  Record ID: {record_id}\")\n",
    "    \n",
    "    try:\n",
    "        digitizer = ECGDigitizer(use_segmented_processing=True, enable_visualization=False)\n",
    "        result = digitizer.process_image(str(image_path))\n",
    "        \n",
    "        signals = {}\n",
    "        for lead_data in result.get('leads', []):\n",
    "            lead_name = lead_data['name']\n",
    "            if lead_name not in LEAD_NAMES:\n",
    "                continue\n",
    "            \n",
    "            signal = np.array(lead_data['values'])\n",
    "            \n",
    "            # Ensure signal is 1D (flatten if 2D)\n",
    "            if signal.ndim > 1:\n",
    "                # If 2D, take the first row or flatten\n",
    "                if signal.shape[0] == 1:\n",
    "                    signal = signal[0]\n",
    "                elif signal.shape[1] == 1:\n",
    "                    signal = signal[:, 0]\n",
    "                else:\n",
    "                    # Multiple rows - take mean or first row\n",
    "                    signal = signal[0] if signal.shape[0] < signal.shape[1] else signal[:, 0]\n",
    "            \n",
    "            # Ensure it's 1D\n",
    "            signal = signal.flatten()\n",
    "            \n",
    "            if len(signal) < SAMPLES_PER_LEAD:\n",
    "                padded = np.zeros(SAMPLES_PER_LEAD)\n",
    "                padded[:len(signal)] = signal\n",
    "                signals[lead_name] = padded\n",
    "            elif len(signal) > SAMPLES_PER_LEAD:\n",
    "                signals[lead_name] = signal[:SAMPLES_PER_LEAD]\n",
    "            else:\n",
    "                signals[lead_name] = signal\n",
    "        \n",
    "        # Fill missing leads\n",
    "        for lead_name in LEAD_NAMES:\n",
    "            if lead_name not in signals:\n",
    "                signals[lead_name] = np.zeros(SAMPLES_PER_LEAD)\n",
    "        \n",
    "        print(f\"   Extracted {len([s for s in signals.values() if np.any(s != 0)])} leads\")\n",
    "        return {'record_id': record_id, 'signals': signals, 'success': True}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        signals = {lead: np.zeros(SAMPLES_PER_LEAD) for lead in LEAD_NAMES}\n",
    "        return {'record_id': record_id, 'signals': signals, 'success': False}\n",
    "\n",
    "# STEP 5: kaggle_cell_5_complete.py\n",
    "\n",
    "# ============================================================================\n",
    "# Main Execution\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Kaggle ECG Digitization Submission\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Find test images\n",
    "test_images = find_test_images()\n",
    "\n",
    "if not test_images:\n",
    "    print(\"\\n No test images found!\")\n",
    "    print(f\"Expected location: {TEST_DIR}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"1. Competition data is attached to notebook\")\n",
    "    print(\"2. Test images are in /kaggle/input/physionet-ecg-image-digitization/test/\")\n",
    "    print(\"\\n  WARNING: No submission.csv will be created without test images!\")\n",
    "    print(\"   The notebook must process at least one test image to generate submission.csv\")\n",
    "else:\n",
    "    print(f\"\\n Found {len(test_images)} test image(s):\")\n",
    "    for img in test_images:\n",
    "        print(f\"  - {img.name}\")\n",
    "    \n",
    "    # Process images\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Processing {len(test_images)} image(s)...\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    results = []\n",
    "    for i, image_path in enumerate(test_images, 1):\n",
    "        print(f\"\\n[{i}/{len(test_images)}] \", end=\"\")\n",
    "        result = process_image(image_path)\n",
    "        results.append(result)\n",
    "    \n",
    "    successful = sum(1 for r in results if r.get('success', False))\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Processing Complete: {successful}/{len(test_images)} images successful\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    \n",
    "    # STEP 5: kaggle_cell_5_complete.py\n",
    "    \n",
    "    # Generate submission.csv\n",
    "    submission_path = OUTPUT_DIR / 'submission.csv'\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Generating submission file...\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    print(f\"Output: {submission_path}\")\n",
    "    \n",
    "    rows_written = 0\n",
    "    total_expected = len(results) * len(LEAD_NAMES) * SAMPLES_PER_LEAD\n",
    "    \n",
    "    with open(submission_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'value'])\n",
    "        \n",
    "        for result_idx, result in enumerate(results, 1):\n",
    "            record_id = result['record_id']\n",
    "            signals = result['signals']\n",
    "            \n",
    "            print(f\"  Writing record {record_id} ({result_idx}/{len(results)})...\", end=\"\")\n",
    "            \n",
    "            record_rows = 0\n",
    "            for lead_name in LEAD_NAMES:\n",
    "                signal = signals[lead_name]\n",
    "                for sample_idx in range(SAMPLES_PER_LEAD):\n",
    "                    row_id = f\"'{record_id}_{sample_idx}_{lead_name}'\"\n",
    "                    value = float(signal[sample_idx])\n",
    "                    writer.writerow([row_id, f\"{value:.6f}\"])\n",
    "                    rows_written += 1\n",
    "                    record_rows += 1\n",
    "            \n",
    "            print(f\" {record_rows:,} rows\")\n",
    "    \n",
    "    print(f\"\\n   Total rows written: {rows_written:,}\")\n",
    "    print(f\"   Expected rows: {total_expected:,}\")\n",
    "    \n",
    "    # Validate submission file\n",
    "    file_size_kb = submission_path.stat().st_size / 1024\n",
    "    file_size_mb = file_size_kb / 1024\n",
    "    expected_rows = len(results) * len(LEAD_NAMES) * SAMPLES_PER_LEAD\n",
    "    \n",
    "    # STEP 5: kaggle_cell_5_complete.py\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\" SUBMISSION COMPLETE! \")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\n Submission File Details:\")\n",
    "    print(f\"   File: {submission_path}\")\n",
    "    print(f\"   Size: {file_size_mb:.2f} MB ({file_size_kb:.2f} KB)\")\n",
    "    print(f\"   Rows: {rows_written:,} (Expected: {expected_rows:,})\")\n",
    "    \n",
    "    if rows_written == expected_rows:\n",
    "        print(f\"    Row count: CORRECT\")\n",
    "    else:\n",
    "        print(f\"    Row count: MISMATCH (Expected {expected_rows:,}, got {rows_written:,})\")\n",
    "    \n",
    "    print(f\"\\n Processing Summary:\")\n",
    "    print(f\"   Records processed: {len(results)}\")\n",
    "    successful = sum(1 for r in results if r.get('success', False))\n",
    "    print(f\"   Successfully processed: {successful}/{len(results)}\")\n",
    "    \n",
    "    print(f\"\\n Record Details:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        status = \"\" if result.get('success') else \"\"\n",
    "        record_id = result['record_id']\n",
    "        leads_count = len([s for s in result['signals'].values() if np.any(s != 0)])\n",
    "        print(f\"   {i}. {status} Record {record_id}: {leads_count} leads extracted\")\n",
    "    \n",
    "    # File validation\n",
    "    print(f\"\\n Validation:\")\n",
    "    print(f\"    File exists: {submission_path.exists()}\")\n",
    "    print(f\"    File readable: {submission_path.is_file()}\")\n",
    "    \n",
    "    # Check first few lines\n",
    "    try:\n",
    "        with open(submission_path, 'r') as f:\n",
    "            first_line = f.readline().strip()\n",
    "            second_line = f.readline().strip()\n",
    "        print(f\"    Header: {first_line}\")\n",
    "        if second_line:\n",
    "            print(f\"    First row: {second_line[:50]}...\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # STEP 5: kaggle_cell_5_complete.py\n",
    "    \n",
    "    # Final verification that submission.csv exists\n",
    "    submission_path = OUTPUT_DIR / 'submission.csv'\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    if submission_path.exists():\n",
    "        file_size_kb = submission_path.stat().st_size / 1024\n",
    "        print(\" READY FOR SUBMISSION!\")\n",
    "        print(f\" submission.csv verified at: {submission_path}\")\n",
    "        print(f\" File size: {file_size_kb:.2f} KB\")\n",
    "    else:\n",
    "        print(\"  WARNING: submission.csv not found!\")\n",
    "        print(f\"   The file should be at: {submission_path}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\n Next Steps:\")\n",
    "    print(f\"   1. Verify submission.csv format is correct\")\n",
    "    print(f\"   2. Check that all test images were processed\")\n",
    "    print(f\"   3. Commit this notebook\")\n",
    "    print(f\"   4. Click 'Submit' button in Kaggle\")\n",
    "\n",
    "# ============================================================================\n",
    "# FILE IDENTIFICATION\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_5_complete.py\n",
    "# Purpose: Complete Cell 5 code for Kaggle notebook (submission code)\n",
    "# Usage: Copy entire file into Cell 5 of Kaggle notebook\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 6: Verification Cell for Kaggle Notebook\n",
    "\n",
    "Copy this ENTIRE file into Cell 6 of your Kaggle notebook.\n",
    "This verifies that submission.csv was created correctly.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 6: Verifying submission.csv\")\n",
    "print(\"=\" * 70)\n",
    "print(\"File: kaggle_cell_6_verify.py\")\n",
    "print(\"Status: Starting...\")\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# STEP 6: kaggle_cell_6_verify.py\n",
    "\n",
    "submission_path = Path('/kaggle/working/submission.csv')\n",
    "\n",
    "# Check if file exists\n",
    "if submission_path.exists():\n",
    "    size_bytes = submission_path.stat().st_size\n",
    "    size_kb = size_bytes / 1024\n",
    "    size_mb = size_kb / 1024\n",
    "    \n",
    "    print(f\"\\n submission.csv FOUND!\")\n",
    "    print(f\"   Path: {submission_path}\")\n",
    "    print(f\"   Size: {size_mb:.2f} MB ({size_kb:.2f} KB, {size_bytes:,} bytes)\")\n",
    "    \n",
    "    # STEP 6: kaggle_cell_6_verify.py\n",
    "    \n",
    "    # Count lines\n",
    "    try:\n",
    "        with open(submission_path, 'r', encoding='utf-8') as f:\n",
    "            lines = sum(1 for _ in f)\n",
    "        print(f\"   Lines: {lines:,}\")\n",
    "        \n",
    "        # Check header\n",
    "        with open(submission_path, 'r', encoding='utf-8') as f:\n",
    "            first_line = f.readline().strip()\n",
    "        print(f\"   Header: {first_line}\")\n",
    "        \n",
    "        if first_line == 'id,value':\n",
    "            print(f\"    Header format: CORRECT\")\n",
    "        else:\n",
    "            print(f\"     Header format: UNEXPECTED (expected 'id,value')\")\n",
    "        \n",
    "        # STEP 6: kaggle_cell_6_verify.py\n",
    "        \n",
    "        # Check if file is empty\n",
    "        if size_bytes == 0:\n",
    "            print(f\"     WARNING: File is EMPTY!\")\n",
    "        elif lines < 2:\n",
    "            print(f\"     WARNING: File has only {lines} line(s) (expected > 1)\")\n",
    "        else:\n",
    "            print(f\"    File appears valid\")\n",
    "            \n",
    "        # Check first few data rows\n",
    "        with open(submission_path, 'r', encoding='utf-8') as f:\n",
    "            header = f.readline()\n",
    "            first_data = f.readline().strip()\n",
    "            second_data = f.readline().strip()\n",
    "        \n",
    "        print(f\"\\n   Sample data rows:\")\n",
    "        print(f\"   Row 1: {first_data[:80]}...\")\n",
    "        print(f\"   Row 2: {second_data[:80]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"     Error reading file: {e}\")\n",
    "    \n",
    "    # STEP 6: kaggle_cell_6_verify.py\n",
    "    \n",
    "    print(f\"\\n READY FOR SUBMISSION!\")\n",
    "    print(f\"   Your notebook should work when you click 'Submit'\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n submission.csv NOT FOUND!\")\n",
    "    print(f\"   Expected location: {submission_path}\")\n",
    "    print(f\"\\n   Possible reasons:\")\n",
    "    print(f\"   1. Cell 5 (submission code) didn't run\")\n",
    "    print(f\"   2. Cell 5 had an error before creating the file\")\n",
    "    print(f\"   3. No test images were found\")\n",
    "    print(f\"   4. File was created in wrong location\")\n",
    "    \n",
    "    # STEP 6: kaggle_cell_6_verify.py\n",
    "    \n",
    "    # Check for files in working directory\n",
    "    print(f\"\\n   Checking /kaggle/working/ for CSV files...\")\n",
    "    working_dir = Path('/kaggle/working')\n",
    "    csv_files = list(working_dir.glob('*.csv'))\n",
    "    if csv_files:\n",
    "        print(f\"   Found {len(csv_files)} CSV file(s):\")\n",
    "        for csv_file in csv_files:\n",
    "            size = csv_file.stat().st_size\n",
    "            print(f\"     - {csv_file.name} ({size / 1024:.2f} KB)\")\n",
    "    else:\n",
    "        print(f\"   No CSV files found in /kaggle/working/\")\n",
    "    \n",
    "    print(f\"\\n    CANNOT SUBMIT - Fix the issue above first\")\n",
    "\n",
    "# STEP 6: kaggle_cell_6_verify.py\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 6: Verification complete!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# FILE IDENTIFICATION\n",
    "# ============================================================================\n",
    "# This file: kaggle_cell_6_verify.py\n",
    "# Purpose: Verification cell to check if submission.csv exists in Kaggle notebook\n",
    "# Usage: Copy entire file into Cell 6 of Kaggle notebook to verify submission file\n",
    "# ============================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0"
  },
  "version": "3.0",
  "name": "ECG Digitization V3"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}